<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sound Wave Simulation</title>
    <!-- Import Three.js library -->
    <script src="three.min.js"></script>
</head>
<body onclick="callSimulation()">
    <script>
        // Your JavaScript code here
        // Import Three.js library

        // Initialize Three.js scene, camera, and renderer
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Create a sound source object (e.g., a sphere)
        const sourceGeometry = new THREE.SphereGeometry(0.1, 32, 32);
        const sourceMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000 });
        const soundSource = new THREE.Mesh(sourceGeometry, sourceMaterial);
        scene.add(soundSource);
        let analyser;

        // Load and play the sound/music file
        async function loadSound(soundURL) {
            debugger;
            try {
                if (analyser == null)
                {
                    // Initialize Web Audio API context
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

                    const response = await fetch(soundURL, {
                        method: "GET",
                        mode: 'cors',
                        headers: {
                            'Content-Type': 'application/json',
                        }
                    });
                    // Decode it
                    arrayBuffer = await audioContext.decodeAudioData(await response.arrayBuffer());
                    audioSource = audioContext.createBufferSource();
                    audioSource.buffer = arrayBuffer;
                    //audioSource.connect(audioContext.destination);

                    // Create AnalyserNode to analyze the audio data
                    analyser = audioContext.createAnalyser();
                    audioSource.connect(analyser);
                    analyser.connect(audioContext.destination);

                    // Start playing the audio
                    audioSource.start();

                    // Simulate sound waves propagation and reflections with input parameters
                    simulateSoundWaves('arcade fire - ready to start.mp3', 20, 1, 0.5);
                }
            } catch (err) {
                console.error(`Unable to fetch the audio file. Error: ${err.message}`);
            }
        }

        // Simulation parameters
        let roomWidth = 45; // Width of the room in meters
        let roomHeight = 43; // Height of the room in meters
        let roomDepth = 44; // Depth of the room in meters
        let soundSpeed = 343; // Speed of sound in air in m/s (at room temperature)
        let distanceToWall = 1; // Distance from the sound source to the wall obstacle in meters
        let wallAbsorptionCoefficient = 0.5; // Coefficient of sound absorption of the walls (range: 0 to 1)

        // Simulate sound wave propagation and reflections
        function simulateSoundWaves(soundURL, roomTemp, wallDistance, absorptionCoefficient) {
            debugger;
            if (!analyser) return;

            // Set simulation parameters based on input
            soundSpeed = 331.4 + (0.6 * roomTemp);
            distanceToWall = wallDistance;
            wallAbsorptionCoefficient = absorptionCoefficient;

            //// Load and play sound/music file
            //loadSound(soundURL);

            for (let x = 0; x < roomWidth; x++) {
                for (let y = 0; y < roomHeight; y++) {
                    for (let z = 0; z < roomDepth; z++) {
                        const listenerPosition = new THREE.Vector3(x, y, z);
                        const distance = soundSource.position.distanceTo(listenerPosition);
                        const timeToReach = distance / soundSpeed;

                        // Calculate direction vector from sound source to listener
                        const direction = listenerPosition.clone().sub(soundSource.position).normalize();

                        // Calculate angle of incidence
                        const angleOfIncidence = Math.acos(direction.dot(new THREE.Vector3(0, 0, 1))) * (180 / Math.PI);

                        // Calculate angle of reflection (assuming perfect reflection off walls)
                        const angleOfReflection = angleOfIncidence;

                        // Create a sphere at the listener position with a delay based on timeToReach
                        setTimeout(() => {
                            const listenerGeometry = new THREE.SphereGeometry(0.05, 16, 16);
                            const listenerMaterial = new THREE.MeshBasicMaterial({ color: 0x0000ff });
                            const listenerSphere = new THREE.Mesh(listenerGeometry, listenerMaterial);

                            // Apply rotation based on angle of reflection
                            listenerSphere.rotateX((angleOfReflection - 90) * (Math.PI / 180));

                            listenerSphere.position.copy(listenerPosition);

                            // Get the frequency data from the analyser
                            const frequencyData = new Uint8Array(analyser.frequencyBinCount);
                            analyser.getByteFrequencyData(frequencyData);

                            // Update the visualization based on the frequency data
                            const averageFrequency = getAverageFrequency(frequencyData);

                            // Calculate scaling factor based on average frequency (adjust as needed)
                            const scaleFactor = averageFrequency / 255; // Normalize to range [0, 1]

                            //// Update size of the sound waves
                            //listenerSphere.scale.set(scaleFactor, scaleFactor, scaleFactor);

                            // Update color of the sound waves (optional)
                            const newColor = new THREE.Color().setHSL(averageFrequency / 255, 1, 0.5); // Adjust color based on average frequency
                            listenerSphere.material.color.copy(newColor);

                            // Update position of the sound waves (optional)
                            const newPosition = new THREE.Vector3(x, y, -2 - averageFrequency * 0.1); // Adjust position based on average frequency
                            listenerSphere.position.copy(newPosition);

                            scene.add(listenerSphere);
                        }, timeToReach * 1000); // Convert time to milliseconds
                    }
                }
            }

            // Call simulateSoundWaves recursively to update the simulation continuously
            requestAnimationFrame(simulateSoundWaves);
        }

        // Function to calculate the average frequency from frequency data
        function getAverageFrequency(frequencyData) {
            let sum = 0;
            for (let i = 0; i < frequencyData.length; i++) {
                sum += frequencyData[i];
            }
            return sum / frequencyData.length;
        }

        // Render loop
        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        function callSimulation()
        {
            // Call the function with the path to your sound/music file
            loadSound('arcade fire - ready to start.mp3');

            // Update camera position
            camera.position.z = 0;

            animate();
        }

    </script>
</body>
</html>
